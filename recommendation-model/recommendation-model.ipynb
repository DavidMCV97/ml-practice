{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Recommendation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "The objective of a Recommendation Model or Recommendation System (RecSys) is to recommend relevant items for users.\n",
    "We will code a RecSys based on the article [Recommender Systems in Python 101](https://www.kaggle.com/code/gspmoreira/recommender-systems-in-python-101) of Gabriel Moreira. We will use the same variable names and some code lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic packages\n",
    "import pandas as pd # dataframe handling\n",
    "import math\n",
    "\n",
    "# modeling packages\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "We will use the \n",
    "[Deskdrop Dataset](https://www.kaggle.com/datasets/gspmoreira/articles-sharing-reading-from-cit-deskdrop)\n",
    "to follow the same steps as in the article. \n",
    "The Deskdrop Dataset contains a real sample of 12 months logs (March 2016 - February 2017) from CI&T's Internal Communication platform (DeskDrop). \n",
    "It consists of the shared articles dataset and the user interactions dataset.\n",
    "The shared articles dataset has information of the articles available on the website.\n",
    "The user interaction has information about user interation to different articles.\n",
    "<br>\n",
    "We will only consider available datasets, to avoid recommending unavaiable articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "\n",
    "# we read the datasets\n",
    "articles_df = pd.read_csv('datasets/shared_articles.csv')\n",
    "interactions_df = pd.read_csv('datasets/users_interactions.csv')\n",
    "\n",
    "# we make sure the analyzed articles are available\n",
    "articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\n",
    "\n",
    "articles_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "This left us with 3,047 available articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Data cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "We will associate to each interation type a weight because \n",
    "some interactions represent higher interest from the user.\n",
    "We will use the same weights proposed in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# event weights\n",
    "event_type_strength = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}\n",
    "\n",
    "# add a column of weight to interactions dataframe\n",
    "interactions_df['eventStrength'] = interactions_df['eventType'].apply(lambda x: event_type_strength[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "To avoid **cold start** (recommending to users with no previous interactions) we will filter for only users with 5+ interactions to different articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df of number of iteractions per user per content\n",
    "users_interactions_count_df = interactions_df.groupby(['personId', 'contentId']).size().groupby('personId').size()\n",
    "\n",
    "# df of users with 5+ interactions\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
    "\n",
    "# we recreate the interactions df with selected users\n",
    "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n",
    "                                                            how = 'right',\n",
    "                                                            on = 'personId')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "This left us with 1895 users.\n",
    "<br>\n",
    "For multiple interactions to the same article, we sum the interation weight of aech interaction and apply a log transform to avoid outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define the log function\n",
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "\n",
    "# we do the sum and apply the log function\n",
    "interactions_full_df = interactions_from_selected_users_df \\\n",
    "                       .groupby(['personId', 'contentId'])['eventStrength'].sum() \\\n",
    "                       .apply(smooth_user_preference).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "To begin with the modeling, we will do an 80-20 split. \n",
    "Some users are really active, so we stratify by user to avoid bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
    "                                   stratify=interactions_full_df['personId'], \n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "We will use the **Top-N accurracy** strategy to evaluate accurracy. \n",
    "We will use N=5 and N=10 and evaluate for each item the user has interacted with.\n",
    "To shorten computational time, we will limmit the recommendation analysis to 100 random selected not-viewed-by-the-user articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample size\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "#Indexing by personId to speed up the searches during evaluation\n",
    "interactions_full_indexed_df = interactions_full_df.set_index('personId')\n",
    "interactions_train_indexed_df = interactions_train_df.set_index('personId')\n",
    "interactions_test_indexed_df = interactions_test_df.set_index('personId')\n",
    "\n",
    "# Get the user's data and merge in the article information.\n",
    "def get_items_interacted(person_id, interactions_df):\n",
    "    interacted_items = interactions_df.loc[person_id]['contentId']\n",
    "    \n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_test = ModelEvaluator()\n",
    "ME_test.get_not_interacted_items_sample(person_id=-8845298781299428018,sample_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use evaluator as an object\n",
    "class ModelEvaluator:\n",
    "\n",
    "    # method to select items the user hasn't interacted with\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
    "        all_items = set(articles_df['contentId'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "'''\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        #Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset['contentId']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(person_id, \n",
    "                                               items_to_ignore=get_items_interacted(person_id, \n",
    "                                                                                    interactions_train_indexed_df), \n",
    "                                               topn=10000000000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        #For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=item_id%(2**32))\n",
    "\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['contentId'].values\n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
    "            person_metrics['_person_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "model_evaluator = ModelEvaluator()    \n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df #.loc[3609194402293569455]['contentId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
